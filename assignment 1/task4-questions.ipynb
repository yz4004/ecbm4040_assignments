{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1, Task 4: Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "A 2 layer MLP is sufficient to model most functions. Why are deep networks used instead of 2 layer networks? \n",
    "\n",
    "   Your answer: Increasing parameters can improve the model to learn more patterns from data. At a certain amount of learning neurons, increasing depth can make model more flexible than just increasing width of shadow layer. Greater depth means more deep pattern can be explored. The two layers model theoretically can fit most function, but sometimes will cost much neurons and calculation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 \n",
    "What are the differences between stochastic gradient descent and Batch gradient descent? Why is mini-batch gradient descent used in practice?\n",
    "\n",
    "   Your answer: Both methods are trying to fit the real gradient and reduce the calculation. Stochastic gradient uses a random sample from dataset each time (assuming sample iid), while batch gradient updates all the data simutaneously instead of one-by-one.\n",
    "   Mini-batch loads part of data in one iteration and changes to another batch in next iteration, which saves the memory, keeps the randomness and walks through the whole data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Why are activation functions used in deep learning? What are the issues that can arise when using sigmoid or tanh activation functions?\n",
    "\n",
    "   Your answer: No activation function will let the whole net being affine/linear, we will train a linear regression, which performs badly on nonlinear patterns. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "What are the differences between linear and logistic regression? Are both linear?\n",
    "\n",
    "   Your answer: Logistic regression is for classification with a linear part plus nonlinear sigmoid activation function. Linear regression is for fitting with no activation function, which is purely linear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Describe your best model in the implementation of the two-layer neural network. Describe your starting point, how you tuned  hyperparameters, which stategies you used to improve the network, show the results of intermediate and the final steps.\n",
    "\n",
    "   Your answer: The default setting already has a good accuracy over 80%. We could created a grid searching for different hyperparameter.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "(Optional, this question is included in the bonus) In tSNE, describe the motivation of tuning the parameter and discuss the difference in results you see.\n",
    "    \n",
    "   Your answer: Perpexity means how many adjacent points our model consider. If we increasing it, more points will be considered as a cluster and the overall plot will be more chaotic.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
